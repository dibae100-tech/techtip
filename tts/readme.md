# Qwen3-TTS Server

í•œêµ­ì–´ ìŒì„± í•©ì„±(TTS) ì„œë²„ - Qwen3-TTS ê¸°ë°˜

## ðŸŽ¯ Features

- **ê³ í’ˆì§ˆ í•œêµ­ì–´ TTS**: Qwen3-TTS 1.7B ëª¨ë¸ ì‚¬ìš©
- **ë¹ ë¥¸ ì‘ë‹µ**: RTX 5060 Ti ê¸°ì¤€ ~1ì´ˆ ì‘ë‹µ
- **REST API**: ê°„ë‹¨í•œ HTTP GET ìš”ì²­ìœ¼ë¡œ ìŒì„± ìƒì„±
- **ë‹¤ì–‘í•œ í™”ìž**: Sohee(í•œêµ­ì–´), Ryan(ì˜ì–´) ë“± 9ì¢… ì§€ì›

## ðŸ“‹ Requirements

- Ubuntu 22.04
- NVIDIA GPU (12GB+ VRAM ê¶Œìž¥)
- CUDA 12.1+
- Python 3.12

## ðŸš€ Quick Start

### 1. Clone

\`\`\`bash
git clone https://github.com/[username]/qwen3-tts-server.git
cd qwen3-tts-server
\`\`\`

### 2. Environment Setup

\`\`\`bash
conda create -n voice-ai python=3.12 -y
conda activate voice-ai
\`\`\`

### 3. Install Dependencies

\`\`\`bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
pip install -U qwen-tts fastapi uvicorn
sudo apt install sox libsox-fmt-all -y
\`\`\`

### 4. Run Server

\`\`\`bash
python tts_server.py
\`\`\`

### 5. Test

\`\`\`bash
curl "http://localhost:42423/tts?text=ì•ˆë…•í•˜ì„¸ìš”" -o test.wav
\`\`\`

## ðŸ“¡ API

### Health Check

\`\`\`
GET /health
\`\`\`

Response:
\`\`\`json
{"status": "ok"}
\`\`\`

### Text-to-Speech

\`\`\`
GET /tts?text={í…ìŠ¤íŠ¸}&speaker={í™”ìž}&seed={ì‹œë“œ}
\`\`\`

| Parameter | Required | Default | Description |
|-----------|----------|---------|-------------|
| text | âœ… | - | ë³€í™˜í•  í…ìŠ¤íŠ¸ |
| speaker | âŒ | Sohee | í™”ìž ì„ íƒ |
| seed | âŒ | None | ìŒì„± ì¼ê´€ì„±ìš© ì‹œë“œê°’ |

Response: \`audio/wav\`

### Example

\`\`\`python
import requests

r = requests.get('http://localhost:42423/tts?text=ì•ˆë…•í•˜ì„¸ìš”')
with open('output.wav', 'wb') as f:
    f.write(r.content)
\`\`\`

## ðŸŽ¤ Available Speakers

| Speaker | Description | Best Language |
|---------|-------------|---------------|
| **Sohee** | ë”°ëœ»í•˜ê³  ê°ì • í’ë¶€í•œ ì—¬ì„± | í•œêµ­ì–´ â­ |
| Vivian | ë°ê³  ì—£ì§€ìžˆëŠ” ì Šì€ ì—¬ì„± | ì¤‘êµ­ì–´ |
| Serena | ë”°ëœ»í•˜ê³  ë¶€ë“œëŸ¬ìš´ ì—¬ì„± | ì¤‘êµ­ì–´ |
| Ryan | ë‹¤ì´ë‚˜ë¯¹í•œ ë‚¨ì„± | ì˜ì–´ |
| Aiden | ë°ì€ ë¯¸êµ­ ë‚¨ì„± | ì˜ì–´ |
| Ono_Anna | ì¼ë³¸ ì—¬ì„± | ì¼ë³¸ì–´ |

## âš¡ Performance

| GPU | Response Time | RTF |
|-----|---------------|-----|
| RTX 5060 Ti 16GB | ~1.0s | ~1.3 |
| RTX 3060 12GB | ~2.4s | ~1.5 |

> RTF (Real-Time Factor): < 1 means faster than realtime

## ðŸ“ Project Structure

\`\`\`
qwen3-tts-server/
â”œâ”€â”€ README.md
â”œâ”€â”€ tts_server.py      # Main server
â”œâ”€â”€ test_tts.py        # Basic test
â”œâ”€â”€ test_speed.py      # Speed benchmark
â””â”€â”€ requirements.txt
\`\`\`

## ðŸ”§ Configuration

ì„œë²„ í¬íŠ¸ ë³€ê²½:

\`\`\`python
# tts_server.py
uvicorn.run(app, host="0.0.0.0", port=42423)  # í¬íŠ¸ ë³€ê²½
\`\`\`

ë°©í™”ë²½ ì„¤ì •:

\`\`\`bash
sudo ufw allow 42423
\`\`\`

## ðŸ§ª Testing

### ê¸°ë³¸ TTS í…ŒìŠ¤íŠ¸

\`\`\`python
# test_tts.py
import torch
import soundfile as sf
from qwen_tts import Qwen3TTSModel

print("ëª¨ë¸ ë¡œë”© ì¤‘...")
model = Qwen3TTSModel.from_pretrained(
    "Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice",
    device_map="cuda:0",
    dtype=torch.float16,
)

print("ìŒì„± ìƒì„± ì¤‘...")
wavs, sr = model.generate_custom_voice(
    text="ì•ˆë…•í•˜ì„¸ìš”, ë°˜ê°‘ìŠµë‹ˆë‹¤! ì €ëŠ” ì¸ê³µì§€ëŠ¥ ìŒì„± ë¹„ì„œìž…ë‹ˆë‹¤.",
    language="Korean",
    speaker="Sohee",
)

sf.write("test_output.wav", wavs[0], sr)
print("ì™„ë£Œ! test_output.wav ìƒì„±ë¨")
\`\`\`

ì‹¤í–‰:
\`\`\`bash
python test_tts.py
aplay test_output.wav
\`\`\`

### ì†ë„ í…ŒìŠ¤íŠ¸

\`\`\`python
# test_speed.py
import torch
import time
from qwen_tts import Qwen3TTSModel

print("ëª¨ë¸ ë¡œë”© ì¤‘...")
model = Qwen3TTSModel.from_pretrained(
    "Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice",
    device_map="cuda:0",
    dtype=torch.float16,
)

texts = [
    "ì•ˆë…•í•˜ì„¸ìš”.",
    "ì•ˆë…•í•˜ì„¸ìš”, ë°˜ê°‘ìŠµë‹ˆë‹¤.",
    "ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ì¸ê³µì§€ëŠ¥ ìŒì„± ë¹„ì„œìž…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
]

print("\n=== ì†ë„ í…ŒìŠ¤íŠ¸ (Sohee) ===\n")

# ì›Œë°ì—…
model.generate_custom_voice(text="í…ŒìŠ¤íŠ¸", language="Korean", speaker="Sohee")

for text in texts:
    start = time.time()
    wavs, sr = model.generate_custom_voice(
        text=text,
        language="Korean",
        speaker="Sohee",
    )
    elapsed = time.time() - start
    audio_duration = len(wavs[0]) / sr
    rtf = elapsed / audio_duration
    
    print(f"í…ìŠ¤íŠ¸: {text}")
    print(f"  ìƒì„± ì‹œê°„: {elapsed:.2f}ì´ˆ | ì˜¤ë””ì˜¤: {audio_duration:.2f}ì´ˆ | RTF: {rtf:.2f}")
    print()
\`\`\`

ì‹¤í–‰:
\`\`\`bash
python test_speed.py
\`\`\`

ì¶œë ¥ ì˜ˆì‹œ:
\`\`\`
=== ì†ë„ í…ŒìŠ¤íŠ¸ (Sohee) ===

í…ìŠ¤íŠ¸: ì•ˆë…•í•˜ì„¸ìš”.
  ìƒì„± ì‹œê°„: 1.44ì´ˆ | ì˜¤ë””ì˜¤: 0.78ì´ˆ | RTF: 1.85

í…ìŠ¤íŠ¸: ì•ˆë…•í•˜ì„¸ìš”, ë°˜ê°‘ìŠµë‹ˆë‹¤.
  ìƒì„± ì‹œê°„: 3.08ì´ˆ | ì˜¤ë””ì˜¤: 2.14ì´ˆ | RTF: 1.44

í…ìŠ¤íŠ¸: ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ì¸ê³µì§€ëŠ¥ ìŒì„± ë¹„ì„œìž…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?
  ìƒì„± ì‹œê°„: 7.57ì´ˆ | ì˜¤ë””ì˜¤: 5.82ì´ˆ | RTF: 1.30
\`\`\`

### ì „ì²´ í™”ìž í…ŒìŠ¤íŠ¸

\`\`\`python
# test_all_voices.py
import torch
import soundfile as sf
from qwen_tts import Qwen3TTSModel

print("ëª¨ë¸ ë¡œë”© ì¤‘...")
model = Qwen3TTSModel.from_pretrained(
    "Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice",
    device_map="cuda:0",
    dtype=torch.float16,
)

speakers = [
    ("Sohee", "ë”°ëœ»í•˜ê³  ê°ì • í’ë¶€í•œ í•œêµ­ ì—¬ì„±"),
    ("Vivian", "ë°ê³  ì—£ì§€ìžˆëŠ” ì Šì€ ì—¬ì„±"),
    ("Serena", "ë”°ëœ»í•˜ê³  ë¶€ë“œëŸ¬ìš´ ì—¬ì„±"),
    ("Ryan", "ë‹¤ì´ë‚˜ë¯¹í•œ ë‚¨ì„±"),
    ("Aiden", "ë°ì€ ë¯¸êµ­ ë‚¨ì„±"),
    ("Ono_Anna", "ì¼ë³¸ ì—¬ì„±"),
]

text = "ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” ì¸ê³µì§€ëŠ¥ ìŒì„± ë¹„ì„œìž…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"

for speaker, desc in speakers:
    print(f"ìƒì„± ì¤‘: {speaker} ({desc})")
    try:
        wavs, sr = model.generate_custom_voice(
            text=text,
            language="Korean",
            speaker=speaker,
        )
        sf.write(f"voice_{speaker}.wav", wavs[0], sr)
        print(f"ì™„ë£Œ: voice_{speaker}.wav")
    except Exception as e:
        print(f"ì‹¤íŒ¨: {speaker} - {e}")

print("\nëª¨ë“  ìŒì„± ìƒì„± ì™„ë£Œ!")
\`\`\`

ì‹¤í–‰:
\`\`\`bash
python test_all_voices.py
\`\`\`

### API ì„œë²„ í…ŒìŠ¤íŠ¸

ì„œë²„ ì‹¤í–‰ í›„ ìƒˆ í„°ë¯¸ë„ì—ì„œ:

\`\`\`bash
# Health Check
curl http://localhost:42423/health

# TTS ìš”ì²­ (Python)
python -c "
import requests
import time

start = time.time()
r = requests.get('http://localhost:42423/tts?text=ì•ˆë…•í•˜ì„¸ìš”')
print(f'ì‘ë‹µ ì‹œê°„: {time.time()-start:.2f}ì´ˆ')
print(f'íŒŒì¼ í¬ê¸°: {len(r.content)} bytes')

with open('test.wav', 'wb') as f:
    f.write(r.content)
print('ì €ìž¥: test.wav')
"

# ìž¬ìƒ
aplay test.wav
\`\`\`

### ì›ê²© ì„œë²„ í…ŒìŠ¤íŠ¸

\`\`\`python
import requests

# ì„œë²„ IPë¡œ ë³€ê²½
SERVER_IP = "192.168.1.34"
PORT = 42423

# Health Check
r = requests.get(f'http://{SERVER_IP}:{PORT}/health')
print(r.json())

# TTS ìš”ì²­
r = requests.get(f'http://{SERVER_IP}:{PORT}/tts?text=ì•ˆë…•í•˜ì„¸ìš”&speaker=Sohee')
with open('remote_test.wav', 'wb') as f:
    f.write(r.content)
print(f'ì €ìž¥ ì™„ë£Œ: {len(r.content)} bytes')
\`\`\`







## ðŸ“š References

- [Qwen3-TTS GitHub](https://github.com/QwenLM/Qwen3-TTS)
- [Qwen3-TTS Blog](https://qwen.ai/blog?id=qwen3tts-0115)
- [Hugging Face Models](https://huggingface.co/collections/Qwen/qwen3-tts)

## ðŸ“„ License

MIT License
